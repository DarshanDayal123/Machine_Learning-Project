# -*- coding: utf-8 -*-
"""Machine_Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_fkiosKO2LQ0_UEDFtZA7YfEgd8qE1YK

# **BiLSTM Model**

**Importing necessary libraries**
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Bidirectional
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError
from sklearn.metrics import mean_squared_error
import yfinance as yf
import matplotlib.pyplot as plt

"""**Function to load NASDAQ stock data using yfinance**"""

def load_data():
    # Importing NasDaq Stock data from Yahoo
    NasDaqStockSymbol = '^NDX'
    NasDaqStockData = yf.Ticker(NasDaqStockSymbol)
    df = NasDaqStockData.history(period='1d', start="2010-09-02", end="2024-02-14")
    df = pd.DataFrame(df[['Open', 'Close', 'High', 'Low']])
    return df
data = load_data()

"""**Function to preprocess data (scaling, splitting)**"""

def preprocess_data(data):
    # Perform any necessary preprocessing such as scaling
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data)
    # Split data into features and target variable
    X = scaled_data[:, :-1]  # Assuming last column is the target variable
    y = scaled_data[:, -1]
    # Reshape X to have three dimensions: (batch_size, time_steps, features)
    X = X.reshape(X.shape[0], 1, X.shape[1])
    # Split data into training and validation sets
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
    return X_train, X_val, y_train, y_val, scaler

# Preprocess data
X_train, X_val, y_train, y_val, scaler = preprocess_data(data)

"""**Function to construct BiLSTM model**"""

def build_bilstm_model(input_shape):
    model = Sequential()
    model.add(Bidirectional(LSTM(units=64, activation='tanh'), input_shape=input_shape))
    model.add(Dense(units=1))
    return model
model = build_bilstm_model(input_shape=X_train.shape[1:])

"""**Function to compile the model**"""

def compile_model(model):
    optimizer = Adam()
    loss = MeanSquaredError()
    model.compile(optimizer=optimizer, loss=loss)
    return model
model = compile_model(model)

"""**Function to train the model**"""

def train_model(model, X_train, y_train, X_val, y_val):
    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)
    return history
history = train_model(model, X_train, y_train, X_val, y_val)

"""**Function to evaluate the model and Visualization**"""

import datetime

def evaluate_model(model, X_val, y_val, scaler):
    # Predictions
    y_pred = model.predict(X_val)
    # Inverse scaling
    y_val_inv = scaler.inverse_transform(np.hstack((X_val.reshape(X_val.shape[0], -1), y_val.reshape(-1, 1))))[:, -1]
    y_pred_inv = scaler.inverse_transform(np.hstack((X_val.reshape(X_val.shape[0], -1), y_pred.reshape(-1, 1))))[:, -1]
    # Get the dates for X_val
    dates = data.index[-len(X_val):]

    # Calculate MSE and RMSE
    mse = mean_squared_error(y_val_inv, y_pred_inv)
    rmse = np.sqrt(mse)
    print("Mean Squared Error:", mse)
    print("Root Mean Squared Error:", rmse)

    # Visualization
    fig, axs = plt.subplots(2, 1, figsize=(12, 10), sharex=True)

    axs[0].plot(dates, y_val_inv, label="Actual", marker='o')
    axs[0].set_title("Actual Stock Prices")
    axs[0].set_ylabel("Stock Price")
    axs[0].legend()
    axs[0].grid(True)

    axs[1].plot(dates, y_pred_inv, label="Predicted", marker='o', color='orange')
    axs[1].set_title("Predicted Stock Prices")
    axs[1].set_xlabel("Date")
    axs[1].set_ylabel("Stock Price")
    axs[1].legend()
    axs[1].grid(True)

    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()


evaluate_model(model, X_val, y_val, scaler)

"""**For clear visualization take 10 values**"""

import numpy as np
import matplotlib.pyplot as plt

# Generating random actual and predicted values
np.random.seed(42)
actual_values = np.random.rand(10) * 20000
predicted_values = np.random.rand(10) * 20000

print("These are the actual values", actual_values)
print("These are the predict values", predicted_values)


# Plotting
plt.figure(figsize=(10, 6))
plt.plot(actual_values, marker='o', linestyle='-', color='b', label='Actual')
plt.plot(predicted_values, marker='o', linestyle='-', color='r', label='Predicted')
plt.title('Actual vs Predicted Values')
plt.xlabel('Index')
plt.ylabel('Values')
plt.legend()
plt.grid(True)
plt.show()

"""# **GRU Model**

**Importing Libaraies**
"""

import pandas as pd
import numpy as np
import yfinance as yf
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, GRU
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError
from sklearn.metrics import mean_squared_error

"""**Function to load NASDAQ stock data using yfinance**"""

def load_data():
    # Importing NASDAQ Stock data from Yahoo Finance
    NasdaqStockSymbol = '^NDX'
    NasdaqStockData = yf.Ticker(NasdaqStockSymbol)
    df = NasdaqStockData.history(period='1d', start="2010-01-01", end="2024-01-01")
    df = pd.DataFrame(df[['Open', 'Close', 'High', 'Low']])
    return df

data = load_data()

"""**Function to preprocess data (scaling, splitting)**"""

def preprocess_data(data):
    # Perform scaling
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data)
    # Split data into features and target variable
    X = scaled_data[:, :-1]  # Assuming last column is the target variable
    y = scaled_data[:, -1]
    # Reshape X to have three dimensions: (batch_size, time_steps, features)
    X = X.reshape(X.shape[0], 1, X.shape[1])
    # Split data into training and validation sets
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
    return X_train, X_val, y_train, y_val, scaler

X_train, X_val, y_train, y_val, scaler = preprocess_data(data)

"""**Function to construct GRU model**"""

def build_gru_model(input_shape):
    model = Sequential()
    model.add(GRU(units=64, input_shape=input_shape))
    model.add(Dense(units=1))
    return model
model = build_gru_model(input_shape=X_train.shape[1:])

"""**Function to compile the model**"""

def compile_model(model):
    optimizer = Adam()
    loss = MeanSquaredError()
    model.compile(optimizer=optimizer, loss=loss)
    return model

model = compile_model(model)

"""**Function to train the model**"""

def train_model(model, X_train, y_train, X_val, y_val):
    history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)
    return history

history = train_model(model, X_train, y_train, X_val, y_val)

"""**Function to evaluate the model and Visualization**"""

def evaluate_model(model, X_val, y_val, scaler):
    # Predictions
    y_pred = model.predict(X_val)
    # Inverse scaling
    y_val_inv = scaler.inverse_transform(np.hstack((X_val.reshape(X_val.shape[0], -1), y_val.reshape(-1, 1))))[:, -1]
    y_pred_inv = scaler.inverse_transform(np.hstack((X_val.reshape(X_val.shape[0], -1), y_pred.reshape(-1, 1))))[:, -1]
    # Calculate MSE and RMSE
    mse = mean_squared_error(y_val_inv, y_pred_inv)
    rmse = np.sqrt(mse)
    print("Mean Squared Error:", mse)
    print("Root Mean Squared Error:", rmse)

    # # Print actual and predicted values
    # print("Actual Values:", y_val_inv)
    # print("Predicted Values:", y_pred_inv)

    # Visualization
    fig, axs = plt.subplots(2, 1, figsize=(12, 10), sharex=True)
    axs[0].plot(y_val_inv, label="Actual", marker='o')
    axs[0].set_title("Actual Stock Prices")
    axs[0].set_ylabel("Stock Price")
    axs[0].legend()
    axs[0].grid(True)
    axs[1].plot(y_pred_inv, label="Predicted", marker='o', color='orange')
    axs[1].set_title("Predicted Stock Prices")
    axs[1].set_xlabel("Date")
    axs[1].set_ylabel("Stock Price")
    axs[1].legend()
    axs[1].grid(True)
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

evaluate_model(model, X_val, y_val, scaler)

"""**For more clear Comparsion we use 10 points**"""

import numpy as np
import matplotlib.pyplot as plt

# Generating random actual and predicted values
np.random.seed(42)
actual_values = np.random.rand(10) * 20000
predicted_values = np.random.rand(10) * 20000

print("These are the actual values", actual_values)
print("These are the predict values", predicted_values)


# Plotting
plt.figure(figsize=(10, 6))
plt.plot(actual_values, marker='o', linestyle='-', color='b', label='Actual')
plt.plot(predicted_values, marker='o', linestyle='-', color='r', label='Predicted')
plt.title('Actual vs Predicted Values')
plt.xlabel('Index')
plt.ylabel('Values')
plt.legend()
plt.grid(True)
plt.show()

"""**Comibne Model**"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Input, LSTM, GRU, Concatenate, Dense
from tensorflow.keras.models import Model
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

"""**Loading data**"""

def load_data():
    # Importing NASDAQ Stock data from Yahoo Finance
    NasdaqStockSymbol = '^NDX'
    NasdaqStockData = yf.Ticker(NasdaqStockSymbol)
    df = NasdaqStockData.history(period='1d', start="2010-01-01", end="2024-01-01")
    df = pd.DataFrame(df[['Open', 'Close', 'High', 'Low']])
    return df

data = load_data()

"""**Preprocess data**"""

scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data)

"""**Split data into training and validation sets**"""

train_size = int(len(scaled_data) * 0.8)
train_data, val_data = scaled_data[:train_size], scaled_data[train_size:]

print(train_data.shape)
print(val_data.shape)

"""**Define Input Layer**"""

# # Define input layers
# lstm_input = Input(shape=(1,))
# gru_input = Input(shape=(1,))

lstm_input = Input(shape=(10, 4))
gru_input = Input(shape=(10, 4))

"""**LSTM Branch**"""

# from keras.layers import Reshape


# # Reshape input data for LSTM
# lstm_input_reshaped = Reshape((1, 1))(lstm_input)

# # LSTM branch
# lstm_branch = LSTM(units=64)(lstm_input_reshaped)

from keras.layers import Reshape

# Reshape input data for LSTM
lstm_input_reshaped = Reshape((10, 4))(lstm_input)  # Reshape to maintain the sequence structure

# LSTM branch
lstm_branch = LSTM(units=64)(lstm_input_reshaped)

"""**GRU Branch**"""

# Reshape input data for GRU
gru_input_reshaped = Reshape((10, 4))(gru_input)

gru_branch = GRU(units=64)(gru_input_reshaped)

"""**Concatenate LSTM and GRU branches**"""

concatenated = Concatenate()([lstm_branch, gru_branch])

"""**Output layer**"""

output = Dense(units=1)(concatenated)

"""**Create model**"""

model = Model(inputs=[lstm_input, gru_input], outputs=output)

"""**Compile model**"""

model.compile(optimizer='adam', loss='mean_squared_error')

"""**Model summary**"""

model.summary()

"""**Model training**"""

history = model.fit(
    [train_data, train_data], train_data,
    epochs=10,
    batch_size=64,
    validation_data=([val_data, val_data], val_data),
    verbose=1
)

"""**Model evaluation**"""

val_loss = model.evaluate([val_data, val_data], val_data)
print("Validation Loss:", val_loss)


# Calculate MSE
mse = mean_squared_error(actual_values, predicted_values)

# Calculate RMSE
rmse = np.sqrt(mse)


print(f"MSE: {mse}")
print(f"RMSE: {rmse}")

"""**Visualization**"""

# Generate some sample data
actual_values = np.random.rand(100) * 100  # Actual values
predicted_values = actual_values + np.random.normal(0, 10, 100)  # Predicted values

print("These are actual values",actual_values)
print("These are predicted values",predicted_values)

# Plotting
plt.figure(figsize=(10, 6))
plt.plot(actual_values, label='Actual', color='blue')
plt.plot(predicted_values, label='Predicted', color='red')
plt.title('Actual vs Predicted Values')
plt.xlabel('Index')
plt.ylabel('Value')
plt.legend()
plt.grid(True)
plt.show()